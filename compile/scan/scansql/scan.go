package scansql

import (
	"fmt"
	"strings"

	"github.com/fioncat/go-gendb/build"
	"github.com/fioncat/go-gendb/compile/token"
	"github.com/fioncat/go-gendb/misc/errors"
	"github.com/fioncat/go-gendb/misc/iter"
	"github.com/fioncat/go-gendb/misc/set"
)

// Result is the result of scanning the sql file.
// Which contains multiple named SQL statements.
// The Result contains the names of all sql statements
// and their token slices. The token slice of the SQL
// statement needs to be further parsed later.
type Result struct {
	// The source file path
	Path string `json:"path"`

	// All sql statements
	Statements []Statement `json:"statements"`

	nameSet *set.Set
}

// Statement represents a SQL statement after lexical
// analysis, which includes the original SQL statement
// and token slices generated by lexical analysis. The
// sql statement here is named. It uses "--! {Name}" to
// mark the name in the sql file. "{name}" cannot be
// empty and will be stored in the Name field.
type Statement struct {
	// The source file path
	Path string `json:"path"`
	// line number of the sql statement
	LineNum int `json:"line_num"`

	// name of the sql
	Name string `json:"name"`

	// tokens
	Tokens   []token.Token `json:"-"`
	TokenStr string        `json:"tokens"`

	// origin sql string
	Origin string `json:"origin"`

	// IsDynamic indicates whether the statement is dynamic,
	// that is, whether there is a dynamic placeholder like
	// "+{xxx}" in it.
	IsDynamic bool
}

// Do performs a scan on a sql file, scans all sql
// statements in it, and performs a lexical analysis on the
// sql statement to generate a token return. Each sql
// statement needs to be marked and separated by "--! {name}".
// The returned Result structure can be passed to the parser
// for grammatical analysis.
func Do(sourcePath, content string) (*Result, error) {
	return file(sourcePath, content)
}

func file(path, content string) (*Result, error) {
	var r Result
	r.Path = path

	sqlConst := make(map[string]string)

	r.nameSet = set.New()
	iter := iter.New(strings.Split(content, "\n"))

	var line string
	for {
		idx := iter.NextP(&line)
		if idx < 0 {
			break
		}
		line = strings.TrimSpace(line)
		if len(line) == 0 {
			continue
		}
		lineNum := idx + 1

		if token.SQL_REUSE_TAG.Prefix(line) {
			name := strings.TrimLeft(line, token.SQL_REUSE_TAG.Get())
			if name == "" {
				return nil, errors.NewComp(path, lineNum,
					"sql const name is empty")
			}
			if _, ok := sqlConst[name]; ok {
				return nil, errors.NewComp(path, lineNum,
					`sql const "%s" is duplicate`, name)
			}

			sqlLines := pickSQL(iter)
			if len(sqlLines) == 0 {
				return nil, errors.NewComp(path, lineNum,
					"sql const '%s' is empty")
			}

			sqlConst[name] = strings.Join(sqlLines, " ")
		}

		if token.SQL_TAG.Prefix(line) ||
			token.SQL_DYNAMIC_TAG.Prefix(line) {

			isDynamic := false
			prefixToken := token.SQL_TAG
			if token.SQL_DYNAMIC_TAG.Prefix(line) {
				prefixToken = token.SQL_DYNAMIC_TAG
				isDynamic = true
			}

			name := strings.TrimLeft(line, prefixToken.Get())
			name = strings.TrimSpace(name)
			if name == "" {
				// we donot allow empty sql name
				return nil, errors.NewComp(path, lineNum,
					"sql name is empty")
			}
			if r.nameSet.Contains(name) {
				// name is duplicate
				return nil, errors.NewComp(path, lineNum,
					`sql name is duplcate for "%s"`, name)
			}
			r.nameSet.Append(name)

			var sm Statement
			sm.Path = path
			sm.LineNum = lineNum
			sm.Name = name
			sm.IsDynamic = isDynamic
			sm.Origin = strings.Join(pickSQL(iter), " ")

			var err error
			if token.SQLPH_REUSE.Contains(sm.Origin) {
				// SQL contains const, handles and replaces them.
				sm.Origin, err = handleConst(path, lineNum,
					sm.Origin, sqlConst)
				if err != nil {
					return nil, err
				}
			}

			sm.Tokens, err = sql(path, lineNum, sm.Origin)
			if err != nil {
				return nil, err
			}

			if build.DEBUG {
				ts := fmt.Sprint(sm.Tokens)
				if len(ts) > 2 {
					ts = ts[1 : len(ts)-1]
					sm.TokenStr = ts
				}
			}

			r.Statements = append(r.Statements, sm)
		}
	}
	return &r, nil
}

func pickSQL(iter *iter.Iter) []string {
	var sqlLines []string
	var pickLine string
	for {
		idx := iter.Pick(&pickLine)
		if idx < 0 {
			break
		}
		if token.SQL_TAG.Prefix(pickLine) ||
			token.SQL_DYNAMIC_TAG.Prefix(pickLine) ||
			token.SQL_REUSE_TAG.Prefix(pickLine) {

			break
		}
		sqlIdx := iter.NextP(&pickLine)
		if sqlIdx < 0 {
			break
		}
		if pickLine == "" ||
			token.SQL_COMMENT.Prefix(pickLine) {
			// ignore empty and comment line
			continue
		}
		sqlLines = append(sqlLines, pickLine)
	}
	return sqlLines
}

const (
	minSQL_len = 7
)

func sql(path string, lineNum int, s string) ([]token.Token, error) {
	scanErr := func(chNum int, msg string, vs ...interface{}) ([]token.Token, error) {
		return nil, errors.NewComp(path, lineNum, msg, vs...).WithCharNum(chNum)
	}

	if len(s) <= minSQL_len {
		return scanErr(-1, "sql length is too small")
	}

	master := s[:minSQL_len-1]
	master = strings.ToUpper(master)
	switch master {
	case token.SQL_UPDATE.Get(), token.SQL_DELETE.Get(),
		token.SQL_INSERT.Get():
		// The modification statement has only a single
		// token that identifies the modification type
		return []token.Token{token.Key(master)}, nil
	case token.SQL_SELECT.Get():
		// ignore

	default:
		return scanErr(0, `unknown start of the sql: "%s"`, master)
	}

	bucket := token.NewBucket()
	bucket.SetKeywords(token.SQL_Keywords)
	iter := iter.New([]rune(s))

	var ch rune
	for {
		idx := iter.NextP(&ch)
		if idx < 0 {
			bucket.Indent()
			break
		}

		if token.SPACE.EqRune(ch) ||
			token.TABLE.EqRune(ch) ||
			token.BREAK.EqRune(ch) {
			// space, \t, \n
			bucket.Indent()
			continue
		}

		switch ch {
		case token.LPAREN.Rune():
			bucket.Key(token.LPAREN)

		case token.RPAREN.Rune():
			bucket.Key(token.RPAREN)

		case token.PERIOD.Rune():
			bucket.Key(token.PERIOD)

		case token.COMMA.Rune():
			bucket.Key(token.COMMA)

		case token.SQUO.Rune():
			fallthrough
		case token.PAUSE.Rune():
			fallthrough
		case token.QUO.Rune():
			bucket.Indent()
			var quotes []rune
			var subch rune
			for iter.Next(&subch) {
				if token.SQUO.EqRune(subch) ||
					token.QUO.EqRune(subch) ||
					token.PAUSE.EqRune(subch) {
					// next ' " `
					break
				}
				quotes = append(quotes, subch)
			}
			bucket.AddToken(token.Indent(string(quotes)))

		default:
			bucket.Append(ch)
		}
	}
	bucket.Indent()
	return bucket.Get(), nil
}

// replace const placeholder(@{name}) into sql section.
func handleConst(path string, line int, sql string, constMap map[string]string) (string, error) {
	iter := iter.New([]rune(sql))
	var bucket []rune

	var ch rune
	var idx int
	for {
		idx = iter.NextP(&ch)
		if idx < 0 {
			break
		}

		if token.SQLPH_REUSE.EqRune(ch) {
			// the next is '{'
			var next rune
			iter.Pick(&next)
			if !token.LBRACE.EqRune(next) {
				bucket = append(bucket, ch)
				continue
			}
			iter.Next(nil)

			var nameBucket []rune
			for {
				idx = iter.NextP(&ch)
				if idx < 0 {
					return "", errors.NewComp(path, line,
						"missing '}'")
				}
				if token.RBRACE.EqRune(ch) {
					break
				}
				nameBucket = append(nameBucket, ch)
			}
			if len(nameBucket) == 0 {
				return "", errors.NewComp(path, line,
					"missing const name").WithCharNum(idx)
			}
			name := string(nameBucket)
			sql, ok := constMap[name]
			if !ok {
				return "", errors.NewComp(path, line,
					`can not find const "%s"`, name).WithCharNum(idx)
			}

			bucket = append(bucket, []rune(sql)...)
			continue
		}
		bucket = append(bucket, ch)
	}
	return string(bucket), nil
}
